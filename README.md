![Lint Status](https://github.com/mnds18/sydney-local-rag-chatbot/actions/workflows/python-lint.yml/badge.svg)


<p align="center">
  <img src="https://img.shields.io/badge/Powered%20By-LangChain-blue" />
  <img src="https://img.shields.io/badge/Vectorstore-FAISS-green" />
  <img src="https://img.shields.io/badge/Language-Python-yellow" />
  <img src="https://img.shields.io/badge/Model-Ollama%20(Local%20LLM)-orange" />
</p>

<br />

# ğŸ¨ Mrig's Sydney Local RAG Chatbot

An end-to-end **Retrieval-Augmented Generation (RAG)** chatbot built **entirely locally** â€” no APIs, no cloud services.  
It reads **PDF** and **Word documents**, builds a **vectorstore**, retrieves answers using **FAISS**, and **generates responses using a local LLM** (Mistral / DeepSeek / Llama3 running in Ollama).

<br />

---

## ğŸš€ Features

- âœ… Full **local-only** document understanding (PDFs + DOCXs)
- âœ… **FAISS** vector database for fast document search
- âœ… **Hard prompting** forcing 1-word or short answers
- âœ… Supports multiple **local LLMs** (DeepSeek, Mistral, Llama3 via Ollama)
- âœ… **Beautiful tourism-themed** front-end chatbot (Flask)
- âœ… Fully **rebuildable vectorstore** on demand
- âœ… Clean, highly commented, production-quality code
- âœ… Designed for **easy personal deployment** or **professional demos**

<br />

---

## ğŸ“‚ Project Structure

```plaintext
.
â”œâ”€â”€ local_chatbot.py      # Main backend: extraction + FAISS + Ollama + Flask
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html        # Frontend chat UI
â”œâ”€â”€ faiss_index/
â”‚   â”œâ”€â”€ faiss.index       # Saved FAISS vector database
â”‚   â””â”€â”€ chunks.pkl        # Saved split document chunks
â”œâ”€â”€ pdf_files/            # Your source PDFs
â”œâ”€â”€ docx_files/           # Your source DOCX files
â”œâ”€â”€ README.md             # You are here :)


ğŸ”‘ Environment Variables
Variable	Purpose
OLLAMA_HOST	Ollama server URL (default: http://localhost:11434)
Ensure Ollama is installed locally with required models downloaded!

ğŸ–¥ï¸ Demo Screenshots

ğŸ—ï¸ Setup Instructions

# 1. Clone repo
git clone https://github.com/yourusername/sydney-local-rag-chatbot.git
cd sydney-local-rag-chatbot

# 2. (Optional) Create virtual environment
python -m venv venv
source venv/bin/activate  # (Linux/Mac)
venv\Scripts\activate     # (Windows)

# 3. Install required packages
pip install -r requirements.txt

# 4. Run the app
python local_chatbot.py


Access chatbot at: http://127.0.0.1:5000

ğŸ›¡ï¸ License
This project is licensed under the MIT License.

ğŸ¤ Contributing
Contributions are welcome! ğŸš€

Please create an issue before submitting pull requests.
Ensure you follow basic Python code style guidelines (flake8).

ğŸ“¢ Acknowledgments
FAISS (Facebook AI Similarity Search)

Sentence Transformers (HuggingFace)

Ollama - Local LLM Runtime

Flask Framework

ğŸ”¥ Connect
If you're passionate about the intersection of
Data Science Ã— AI Engineering Ã— Product Thinking â€” let's connect!
Always building smart, offline-first AI products! ğŸš€

LinkedIn : https://www.linkedin.com/in/mrigendranath/

